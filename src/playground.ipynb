{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import rff\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.299634  [   64/60000]\n",
      "loss: 2.299810  [ 6464/60000]\n",
      "loss: 2.276370  [12864/60000]\n",
      "loss: 2.278308  [19264/60000]\n",
      "loss: 2.247635  [25664/60000]\n",
      "loss: 2.224812  [32064/60000]\n",
      "loss: 2.233437  [38464/60000]\n",
      "loss: 2.195992  [44864/60000]\n",
      "loss: 2.185740  [51264/60000]\n",
      "loss: 2.164205  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.1%, Avg loss: 2.160504 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.165354  [   64/60000]\n",
      "loss: 2.165559  [ 6464/60000]\n",
      "loss: 2.099150  [12864/60000]\n",
      "loss: 2.123393  [19264/60000]\n",
      "loss: 2.057441  [25664/60000]\n",
      "loss: 2.006664  [32064/60000]\n",
      "loss: 2.037393  [38464/60000]\n",
      "loss: 1.950215  [44864/60000]\n",
      "loss: 1.947223  [51264/60000]\n",
      "loss: 1.888301  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.2%, Avg loss: 1.886476 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.911744  [   64/60000]\n",
      "loss: 1.894083  [ 6464/60000]\n",
      "loss: 1.761536  [12864/60000]\n",
      "loss: 1.817104  [19264/60000]\n",
      "loss: 1.689472  [25664/60000]\n",
      "loss: 1.652105  [32064/60000]\n",
      "loss: 1.677514  [38464/60000]\n",
      "loss: 1.569481  [44864/60000]\n",
      "loss: 1.588416  [51264/60000]\n",
      "loss: 1.500999  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.7%, Avg loss: 1.517796 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.577198  [   64/60000]\n",
      "loss: 1.555140  [ 6464/60000]\n",
      "loss: 1.393144  [12864/60000]\n",
      "loss: 1.480139  [19264/60000]\n",
      "loss: 1.346454  [25664/60000]\n",
      "loss: 1.355902  [32064/60000]\n",
      "loss: 1.368478  [38464/60000]\n",
      "loss: 1.288890  [44864/60000]\n",
      "loss: 1.317985  [51264/60000]\n",
      "loss: 1.235852  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.3%, Avg loss: 1.260250 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.333542  [   64/60000]\n",
      "loss: 1.322942  [ 6464/60000]\n",
      "loss: 1.149840  [12864/60000]\n",
      "loss: 1.265214  [19264/60000]\n",
      "loss: 1.126975  [25664/60000]\n",
      "loss: 1.166605  [32064/60000]\n",
      "loss: 1.180740  [38464/60000]\n",
      "loss: 1.116763  [44864/60000]\n",
      "loss: 1.149772  [51264/60000]\n",
      "loss: 1.080395  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.0%, Avg loss: 1.100124 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.169620  [   64/60000]\n",
      "loss: 1.176323  [ 6464/60000]\n",
      "loss: 0.988904  [12864/60000]\n",
      "loss: 1.129526  [19264/60000]\n",
      "loss: 0.988674  [25664/60000]\n",
      "loss: 1.036803  [32064/60000]\n",
      "loss: 1.062127  [38464/60000]\n",
      "loss: 1.005758  [44864/60000]\n",
      "loss: 1.037738  [51264/60000]\n",
      "loss: 0.980599  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.994902 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.052486  [   64/60000]\n",
      "loss: 1.079845  [ 6464/60000]\n",
      "loss: 0.877061  [12864/60000]\n",
      "loss: 1.037724  [19264/60000]\n",
      "loss: 0.900103  [25664/60000]\n",
      "loss: 0.943529  [32064/60000]\n",
      "loss: 0.982703  [38464/60000]\n",
      "loss: 0.932646  [44864/60000]\n",
      "loss: 0.958195  [51264/60000]\n",
      "loss: 0.912269  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.3%, Avg loss: 0.921871 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.964467  [   64/60000]\n",
      "loss: 1.011460  [ 6464/60000]\n",
      "loss: 0.796222  [12864/60000]\n",
      "loss: 0.971433  [19264/60000]\n",
      "loss: 0.840169  [25664/60000]\n",
      "loss: 0.873351  [32064/60000]\n",
      "loss: 0.925470  [38464/60000]\n",
      "loss: 0.882836  [44864/60000]\n",
      "loss: 0.899103  [51264/60000]\n",
      "loss: 0.861691  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.6%, Avg loss: 0.868287 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.895697  [   64/60000]\n",
      "loss: 0.959302  [ 6464/60000]\n",
      "loss: 0.735064  [12864/60000]\n",
      "loss: 0.921237  [19264/60000]\n",
      "loss: 0.797245  [25664/60000]\n",
      "loss: 0.819445  [32064/60000]\n",
      "loss: 0.881241  [38464/60000]\n",
      "loss: 0.847809  [44864/60000]\n",
      "loss: 0.854044  [51264/60000]\n",
      "loss: 0.822138  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 68.7%, Avg loss: 0.827216 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.840382  [   64/60000]\n",
      "loss: 0.917206  [ 6464/60000]\n",
      "loss: 0.686946  [12864/60000]\n",
      "loss: 0.881646  [19264/60000]\n",
      "loss: 0.764571  [25664/60000]\n",
      "loss: 0.777045  [32064/60000]\n",
      "loss: 0.845686  [38464/60000]\n",
      "loss: 0.822073  [44864/60000]\n",
      "loss: 0.818534  [51264/60000]\n",
      "loss: 0.789880  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.0%, Avg loss: 0.794396 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_xi(nin, nout, sigma=1):\n",
    "    return torch.randn((nout, nin)) * sigma\n",
    "\n",
    "@torch.jit.script\n",
    "def RandomFourierFeatureMap(xi: torch.Tensor, x: torch.Tensor):\n",
    "    assert xi.shape[1] == x.shape[0]\n",
    "    return torch.cos(torch.matmul(xi, x))\n",
    "\n",
    "class RandomFourierFeatureLayer(nn.Module):\n",
    "    def __init__(self, nin, nout, sigma=1) -> None:\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"xi\", sample_xi(nin, nout, sigma))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return RandomFourierFeatureMap(self.xi, x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = sample_xi(3, 10, sigma=1)\n",
    "x = torch.tensor([1,2,3], dtype=torch.float32)\n",
    "RandomFourierFeatureMap(xi, x)\n",
    "t = RandomFourierFeatureLayer(3, 10, sigma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9377,  0.9937, -0.0632, -0.0609,  0.8517,  0.4634, -0.4303, -0.9407,\n",
       "        -0.8976,  0.9990])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56fab21abc726fd577125cf91d91a2f1229829a034e6cc30b49fd28490a8b724"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
